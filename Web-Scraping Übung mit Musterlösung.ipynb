{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungen zu Web-Scraping mit BeautifulSoup\n",
    "\n",
    "## Aufgabe 1 - Theorie\n",
    "\n",
    "Beantworten sie bitte folgende Fragen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Was ist Web-Scraping?\n",
    "2. Was ist beim Scrapen erlaubt?\n",
    "3. Finden Sie noch andere Anwendungsbeipspiele?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Web Scraping ist die automatische Extraktion von Daten in einem Format, das man leicht für Analysen und weitere Bearbeitungen nutzen kann.\n",
    "> 2. Es ist rechtlich völlig in Ordnung, wenn Daten von fremden Webseiten geholt werden (keine Urheberrechte verletzen, keine technischen Maßnahmen zur Sperrung der Daten umgehen) so lange sich die Nutzung im Rahmen einer normalen Auswertung der Datenbank hält und die berechtigten Interessen des anderen nicht unzumutbar beeinträchtigt werden.\n",
    "> 3. *offene Frage ohne Wertung*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 - Anwendung\n",
    "\n",
    "Besuchen Sie zunächst folgende [Seite](http://econpy.pythonanywhere.com/ex/001.html) und sammeln Sie diese Daten in einem   `Dataframe`.\n",
    "\n",
    "Zum Einstieg erstmal nur die Daten der ersten angezeigten Webseite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('http://econpy.pythonanywhere.com/ex/001.html')\n",
    "\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# soup.contents # for HTML-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "all_buyers = soup.find_all(\"div\", attrs={\"title\": \"buyer-name\"})\n",
    "all_prices = soup.find_all(\"span\", attrs={\"class\": \"item-price\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buyer = []\n",
    "for a in all_buyers:\n",
    "    buyers = a.string.strip()\n",
    "    buyer.append(buyers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "price = []\n",
    "for a in all_prices:\n",
    "    prices = a.string.strip()\n",
    "    price.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Käufer</th>\n",
       "      <th>Preis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carson Busses</td>\n",
       "      <td>$29.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earl E. Byrd</td>\n",
       "      <td>$8.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patty Cakes</td>\n",
       "      <td>$15.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Derri Anne Connecticut</td>\n",
       "      <td>$19.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moe Dess</td>\n",
       "      <td>$19.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Käufer   Preis\n",
       "0           Carson Busses  $29.95\n",
       "1            Earl E. Byrd   $8.37\n",
       "2             Patty Cakes  $15.26\n",
       "3  Derri Anne Connecticut  $19.25\n",
       "4                Moe Dess  $19.25"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_df = pd.DataFrame(data={'Käufer':buyer,'Preis':price})\n",
    "info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und nun probieren Sie sich daran, auch sämtliche Daten der anderen 4 Seiten zu holen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ['http://econpy.pythonanywhere.com/ex/002.html', \n",
    "       'http://econpy.pythonanywhere.com/ex/003.html', \n",
    "       'http://econpy.pythonanywhere.com/ex/004.html', \n",
    "       'http://econpy.pythonanywhere.com/ex/005.html']\n",
    "\n",
    "for pg in url:\n",
    "    page = requests.get(pg)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    all_buyers= soup.find_all(\"div\", attrs={\"title\": \"buyer-name\"})\n",
    "    all_prices= soup.find_all(\"span\", attrs={\"class\": \"item-price\"})\n",
    "    for a in all_buyers:\n",
    "        buyers = a.string.strip()\n",
    "        buyer.append(buyers)\n",
    "    for a in all_prices:\n",
    "        prices = a.string.strip()\n",
    "        price.append(prices)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.DataFrame(data={'Käufer':buyer,'Preis':price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Käufer</th>\n",
       "      <th>Preis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Missy Perriad</td>\n",
       "      <td>$15.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Carolina Rice</td>\n",
       "      <td>$28.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Anna Septic</td>\n",
       "      <td>$19.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Cass Tigate</td>\n",
       "      <td>$25.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Val Voline</td>\n",
       "      <td>$26.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Käufer   Preis\n",
       "95  Missy Perriad  $15.60\n",
       "96  Carolina Rice  $28.12\n",
       "97    Anna Septic  $19.97\n",
       "98    Cass Tigate  $25.70\n",
       "99     Val Voline  $26.28"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
